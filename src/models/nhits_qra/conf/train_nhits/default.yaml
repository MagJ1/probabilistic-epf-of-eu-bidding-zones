n_epochs: 100
batch_size: 128
num_workers: 4
persistent_workers: false
gradient_clip_val: 1.0
accumulate_grad_batches: 1
enable_progress_bar: false

lr: 1e-3
warmup_epochs: 2

loss: mae                # {mse, mae}
val_metric: mae          # {mse, mae}  # if ever set {crps, es}, config key for sampling during eval would be necessary

sample_dropout: false     # enable MC dropout at inference

include_flags_ctx: false
include_static: false

log_every_n_steps: 10
num_sanity_val_steps: 2

early_stopping: true
early_patience: 20
early_min_delta: 0.001


swag:
  enabled: true
  start_epoch: 5
  collect_every: 1
  max_rank: 20
  var_clamp: 1e-30
  scale: 1.0